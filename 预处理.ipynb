{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5048569c",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78693e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightkurve as lk\n",
    "import tensorflow as tf\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a66fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_split(filename,gap_width):\n",
    "    table = fits.getdata(filename)\n",
    "    time = table['TIME']\n",
    "    flux = table['PDCSAP_FLUX']\n",
    "    q_lst = table['QUALITY']\n",
    "    m = q_lst == 0\n",
    "    time = time[m]\n",
    "    flux = flux[m]\n",
    "    m2 = ~np.isnan(flux)\n",
    "    all_time = time[m2]\n",
    "    all_flux = flux[m2]\n",
    "    \n",
    "    # Handle single-segment inputs.\n",
    "    if isinstance(all_time, np.ndarray) and all_time.ndim == 1:\n",
    "        all_time = [all_time]\n",
    "        all_flux = [all_flux]\n",
    "\n",
    "    out_time = []\n",
    "    out_flux = []\n",
    "    for time, flux in zip(all_time, all_flux):\n",
    "        start = 0\n",
    "        for end in range(1, len(time) + 1):\n",
    "            # Choose the largest endpoint such that time[start:end] has no gaps.\n",
    "            if end == len(time) or time[end] - time[end - 1] > gap_width:\n",
    "                out_time.append(time[start:end])\n",
    "                out_flux.append(flux[start:end])\n",
    "                start = end\n",
    "\n",
    "    return out_time, out_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e439812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_mean(y, cut):\n",
    "    \"\"\"Computes a robust mean estimate in the presence of outliers.\n",
    "    Args:\n",
    "        y: 1D numpy array. Assumed to be normally distributed with outliers.\n",
    "        cut: Points more than this number of standard deviations from the median areignored.\n",
    "    Returns:\n",
    "        mean: A robust estimate of the mean of y.\n",
    "        mean_stddev: The standard deviation of the mean.\n",
    "        mask: Boolean array with the same length as y. Values corresponding tooutliers in y are False. All other values are True.\n",
    "    \"\"\"\n",
    "    # First, make a robust estimate of the standard deviation of y, assuming y is\n",
    "    # normally distributed. The conversion factor of 1.4826 takes the median\n",
    "    # absolute deviation to the standard deviation of a normal distribution.\n",
    "    # See, e.g. https://www.mathworks.com/help/stats/mad.html.\n",
    "    absdev = np.abs(y - np.median(y))\n",
    "    sigma = 1.4826 * np.median(absdev)\n",
    "\n",
    "    # If the previous estimate of the standard deviation using the median absolute\n",
    "    # deviation is zero, fall back to a robust estimate using the mean absolute\n",
    "    # deviation. This estimator has a different conversion factor of 1.253.\n",
    "    # See, e.g. https://www.mathworks.com/help/stats/mad.html.\n",
    "    if sigma < 1.0e-24:\n",
    "        sigma = 1.253 * np.mean(absdev)\n",
    "\n",
    "    # Identify outliers using our estimate of the standard deviation of y.\n",
    "    mask = absdev <= cut * sigma\n",
    "\n",
    "    # Now, recompute the standard deviation, using the sample standard deviation\n",
    "    # of non-outlier points.\n",
    "    sigma = np.std(y[mask])\n",
    "\n",
    "    # Compensate the estimate of sigma due to trimming away outliers. The\n",
    "    # following formula is an approximation, see\n",
    "    # http://w.astro.berkeley.edu/~johnjohn/idlprocs/robust_mean.pro.\n",
    "    sc = np.max([cut, 1.0])\n",
    "    if sc <= 4.5:\n",
    "        sigma /= (-0.15405 + 0.90723 * sc - 0.23584 * sc**2 + 0.020142 * sc**3)\n",
    "\n",
    "    # Identify outliers using our second estimate of the standard deviation of y.\n",
    "    mask = absdev <= cut * sigma\n",
    "\n",
    "    # Now, recompute the standard deviation, using the sample standard deviation\n",
    "    # with non-outlier points.\n",
    "    sigma = np.std(y[mask])\n",
    "\n",
    "    # Compensate the estimate of sigma due to trimming away outliers.\n",
    "    sc = np.max([cut, 1.0])\n",
    "    if sc <= 4.5:\n",
    "        sigma /= (-0.15405 + 0.90723 * sc - 0.23584 * sc**2 + 0.020142 * sc**3)\n",
    "\n",
    "    # Final estimate is the sample mean with outliers removed.\n",
    "    mean = np.mean(y[mask])\n",
    "    mean_stddev = sigma / np.sqrt(len(y) - 1.0)\n",
    "\n",
    "    return mean, mean_stddev, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a82954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lc(time,flux,outlier_cut,flux_len):\n",
    "    '''\n",
    "    time 一维时间序列\n",
    "    flux 一维光变曲线\n",
    "    outlier_cut 与中位数的最大标准差数点之前的样条残差被认为是离群值。\n",
    "    \n",
    "    '''\n",
    "    # 将时间归一化至[0, 1].\n",
    "    t_min = np.min(time)\n",
    "    t_max = np.max(time)\n",
    "    time = (time - t_min) / (t_max - t_min)\n",
    "\n",
    "    #mask是一个bool型向量，其中TRUE表示用来参与插值拟合的数据\n",
    "    mask = np.ones_like(time, dtype=np.bool_)\n",
    "    \n",
    "    #迭代地拟合样条\n",
    "    maxiter=3#迭代次数\n",
    "    for _ in range(maxiter):\n",
    "        time = time[mask]\n",
    "        flux = flux[mask]\n",
    "        spl = InterpolatedUnivariateSpline(time, flux)\n",
    "        fit = spl(time)\n",
    "        residuals = flux - fit\n",
    "        new_mask = robust_mean(residuals, cut=outlier_cut)[2]\n",
    "        # if np.all(new_mask == mask):\n",
    "        #     break  # Spline converged.\n",
    "        mask = new_mask\n",
    "    \n",
    "    #利用拟合好的样条产生模拟数据\n",
    "    x = np.linspace(0, 1, flux_len)\n",
    "    fit_flux = spl(x)\n",
    "    \n",
    "    #归一化光变曲线\n",
    "    f_max = max(fit_flux)\n",
    "    f_min = min(fit_flux)\n",
    "    f = (fit_flux - f_min)/(f_max - f_min)\n",
    "    \n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b256e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按比例取部分数据，ratio：0-100，保留数据的比例\n",
    "def dropMax(t,f,ratio):\n",
    "    mask = f < np.percentile(f, ratio)\n",
    "    f = f[mask]\n",
    "    t = t[mask]\n",
    "    return t,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb59673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def writeData(data,csv_file):\n",
    "    # 如果文件不存在，新建一个\n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "    # 写入行数据\n",
    "    with open(csv_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ba5a3",
   "metadata": {},
   "source": [
    "# lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "059eaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将划分好的lc数据存入文件中\n",
    "gap_width = 0.75 #linagyu代码中引用\n",
    "outlier_cut = 3\n",
    "flux_len = 4000\n",
    "labelLst = ['EA','EB','EW']\n",
    "\n",
    "    \n",
    "def getProcessedData(label,gap_width,outlier_cut,flux_len):\n",
    "    dir = \"./labeledLcData/\"+label+'/'\n",
    "    #将划分好的lc数据存入文件中\n",
    "    csv_file = './processedData_4000/'+label+'.csv'\n",
    "    fileLst = os.listdir(dir)\n",
    "    for file in fileLst:\n",
    "        filename = dir + file\n",
    "        out_time,out_flux = lc_split(filename,gap_width)\n",
    "        for t,f in zip(out_time,out_flux):\n",
    "            if len(t) >= 2000:\n",
    "                t,f = dropMax(t,f,99)\n",
    "                final_flux = process_lc(t,f,outlier_cut,flux_len)\n",
    "                writeData(final_flux,csv_file)\n",
    "                \n",
    "for label in labelLst:\n",
    "    getProcessedData(label,gap_width,outlier_cut,flux_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51913529",
   "metadata": {},
   "source": [
    "# GLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0101b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import periodogram\n",
    "\n",
    "\n",
    "def getGLSData(label,gap_width,period_lst):\n",
    "    dir = \"./labeledLcData/\"+label+'/'\n",
    "    #将划分好的lc数据存入文件中\n",
    "    csv_file = './GLSdata_1000/'+ 'new_' + label+'.csv'\n",
    "    fileLst = os.listdir(dir)\n",
    "    for file in fileLst:\n",
    "        filename = dir + file\n",
    "        out_time,out_flux = lc_split(filename,gap_width)\n",
    "        for t,f in zip(out_time,out_flux):\n",
    "            t,f = dropMax(t,f,99)\n",
    "            if len(t) >= 2000:\n",
    "                t,f = dropMax(t,f,99)\n",
    "                pdm = periodogram.GLS(t, f)\n",
    "                power, winpower = pdm.get_power(period=period_lst)\n",
    "                #power归一化\n",
    "                p_max = max(power)\n",
    "                p_min = min(power)\n",
    "                p = (power - p_min)/(p_max - p_min)\n",
    "                writeData(p,csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1caee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelLst = ['EA','EB','EW']\n",
    "gap_width = 0.75\n",
    "period_lst = np.logspace(-3, 1, 1125)[125:]\n",
    "\n",
    "for label in labelLst:\n",
    "    getGLSData(label,gap_width,period_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40909dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e2d543",
   "metadata": {},
   "source": [
    "# all TESS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68980431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将扇区数据进行lc预处理和获得GLS周期提数据，并保存\n",
    "def getProcessedData(sec,gap_width,outlier_cut,flux_len,period_lst):\n",
    "    #存入文件位置\n",
    "    lc_csv_file = 'F:/tess/processedData/lc/'+sec+'.csv'\n",
    "    GLS_csv_file = 'F:/tess/processedData/GLS/'+sec+'.csv'\n",
    "    \n",
    "    dir = \"F:/tess/lc/\"+sec+'/'\n",
    "    fileLst = os.listdir(dir)\n",
    "    for file in fileLst:\n",
    "        filename = dir + file\n",
    "        out_time,out_flux = lc_split(filename,gap_width)\n",
    "        for t,f in zip(out_time,out_flux):\n",
    "            if len(t) >= 2000:\n",
    "                t,f = dropMax(t,f,99)#去除离群\n",
    "                #lc预处理并保存,保存时第一列保存文件名\n",
    "                final_flux = process_lc(t,f,outlier_cut,flux_len)\n",
    "                save_flux = [file]+list(final_flux)\n",
    "                writeData(save_flux,lc_csv_file)\n",
    "                \n",
    "                #获取power，GLS数据，并保存\n",
    "                pdm = periodogram.GLS(t, f)\n",
    "                power, winpower = pdm.get_power(period=period_lst)\n",
    "                #power归一化\n",
    "                p_max = max(power)\n",
    "                p_min = min(power)\n",
    "                p = (power - p_min)/(p_max - p_min)\n",
    "                save_power = [file]+list(p)\n",
    "                writeData(save_power,GLS_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import periodogram\n",
    "#将划分好的lc数据存入文件中\n",
    "gap_width = 0.75 #linagyu代码中引用\n",
    "outlier_cut = 3\n",
    "flux_len = 4000\n",
    "period_lst = np.logspace(-3, 1, 1125)[125:]\n",
    "\n",
    "sectorlst = ['s075']\n",
    "\n",
    "for sec in sectorlst:\n",
    "    getProcessedData(sec,gap_width,outlier_cut,flux_len,period_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662881c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "cae380bebe6226c23c606d6f31ea40e17fed3962063ae5af630e3d6f79419451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
