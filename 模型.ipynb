{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import metrics\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get trainData and testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainTestData(dataName,labelName):\n",
    "    data = pd.read_csv('./train_test_data/' + dataName + '.csv',header = None)\n",
    "    x = np.array(data)\n",
    "    #change data format\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    X = tf.expand_dims(x, 2)\n",
    "\n",
    "    label = pd.read_csv('./train_test_data/' + labelName + '.csv',header = None)\n",
    "    y = np.array(label[0])\n",
    "    Y = np_utils.to_categorical(y, 2)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_trainX,f_trainY = loadTrainTestData('lc_trainX','lc_trainY')\n",
    "f_testX,f_testY = loadTrainTestData('lc_testX','lc_testY')\n",
    "g_trainX,g_trainY = loadTrainTestData('gls_trainX','gls_trainY')\n",
    "g_testX,g_testY = loadTrainTestData('gls_testX','gls_testY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 30  #epoch\n",
    "# metrics\n",
    "METRICS = [\n",
    "    metrics.BinaryAccuracy(name='accuracy'),\n",
    "    metrics.Precision(name='precision'),\n",
    "    metrics.Recall(name='recall'),\n",
    "    metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model1-CBAM+LSTM+add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBAM(x,filter_num,reduction_ratio):\n",
    "    # Channel Attention\n",
    "    avgpool = GlobalAveragePooling1D()(x)\n",
    "    maxpool = GlobalMaxPooling1D()(x)\n",
    "    # Shared MLP\n",
    "    Dense_layer1 = Dense(filter_num//reduction_ratio, activation='relu')\n",
    "    Dense_layer2 = Dense(filter_num, activation='relu')\n",
    "    avg_out = Dense_layer2(Dense_layer1(avgpool))\n",
    "    max_out = Dense_layer2(Dense_layer1(maxpool))\n",
    "\n",
    "    channel = Add()([avg_out, max_out])\n",
    "    channel = Activation('sigmoid')(channel)\n",
    "    channel_out = Multiply()([x, channel])\n",
    "\n",
    "    # Spatial Attention\n",
    "    avgpool = tf.reduce_mean(channel_out, axis=1, keepdims=True)\n",
    "    maxpool = tf.reduce_max(channel_out, axis=1, keepdims=True)\n",
    "    spatial = Concatenate()([avgpool, maxpool])\n",
    "\n",
    "    spatial = Conv1D(1, kernel_size=8, padding='SAME')(spatial)\n",
    "    spatial_out = Activation('sigmoid',)(spatial)\n",
    "\n",
    "    CBAM_out = tf.multiply(channel_out, spatial_out)\n",
    "    return CBAM_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "574/574 [==============================] - 2262s 4s/step - loss: 0.3059 - accuracy: 0.8732 - precision: 0.8732 - recall: 0.8732 - auc: 0.9413 - val_loss: 0.2436 - val_accuracy: 0.9081 - val_precision: 0.9081 - val_recall: 0.9081 - val_auc: 0.9571\n",
      "Epoch 2/30\n",
      "574/574 [==============================] - 2005s 3s/step - loss: 0.2337 - accuracy: 0.9130 - precision: 0.9130 - recall: 0.9130 - auc: 0.9618 - val_loss: 0.2028 - val_accuracy: 0.9231 - val_precision: 0.9231 - val_recall: 0.9231 - val_auc: 0.9700\n",
      "Epoch 3/30\n",
      "574/574 [==============================] - 1714s 3s/step - loss: 0.1901 - accuracy: 0.9332 - precision: 0.9332 - recall: 0.9332 - auc: 0.9718 - val_loss: 0.1681 - val_accuracy: 0.9433 - val_precision: 0.9433 - val_recall: 0.9433 - val_auc: 0.9752\n",
      "Epoch 4/30\n",
      "574/574 [==============================] - 1786s 3s/step - loss: 0.1695 - accuracy: 0.9428 - precision: 0.9428 - recall: 0.9428 - auc: 0.9751 - val_loss: 0.1566 - val_accuracy: 0.9485 - val_precision: 0.9485 - val_recall: 0.9485 - val_auc: 0.9766\n",
      "Epoch 5/30\n",
      "574/574 [==============================] - 1598s 3s/step - loss: 0.1579 - accuracy: 0.9484 - precision: 0.9484 - recall: 0.9484 - auc: 0.9769 - val_loss: 0.1442 - val_accuracy: 0.9520 - val_precision: 0.9520 - val_recall: 0.9520 - val_auc: 0.9787\n",
      "Epoch 6/30\n",
      "574/574 [==============================] - 1423s 2s/step - loss: 0.1494 - accuracy: 0.9516 - precision: 0.9516 - recall: 0.9516 - auc: 0.9783 - val_loss: 0.1362 - val_accuracy: 0.9567 - val_precision: 0.9567 - val_recall: 0.9567 - val_auc: 0.9805\n",
      "Epoch 7/30\n",
      "574/574 [==============================] - 1532s 3s/step - loss: 0.1439 - accuracy: 0.9536 - precision: 0.9536 - recall: 0.9536 - auc: 0.9795 - val_loss: 0.1404 - val_accuracy: 0.9550 - val_precision: 0.9550 - val_recall: 0.9550 - val_auc: 0.9803\n",
      "Epoch 8/30\n",
      "574/574 [==============================] - 1597s 3s/step - loss: 0.1387 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - auc: 0.9804 - val_loss: 0.1296 - val_accuracy: 0.9588 - val_precision: 0.9588 - val_recall: 0.9588 - val_auc: 0.9821\n",
      "Epoch 9/30\n",
      "574/574 [==============================] - 1409s 2s/step - loss: 0.1308 - accuracy: 0.9584 - precision: 0.9584 - recall: 0.9584 - auc: 0.9819 - val_loss: 0.1260 - val_accuracy: 0.9609 - val_precision: 0.9609 - val_recall: 0.9609 - val_auc: 0.9832\n",
      "Epoch 10/30\n",
      "574/574 [==============================] - 1660s 3s/step - loss: 0.1270 - accuracy: 0.9600 - precision: 0.9600 - recall: 0.9600 - auc: 0.9824 - val_loss: 0.1182 - val_accuracy: 0.9631 - val_precision: 0.9631 - val_recall: 0.9631 - val_auc: 0.9833\n",
      "Epoch 11/30\n",
      "574/574 [==============================] - 1541s 3s/step - loss: 0.1222 - accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - auc: 0.9835 - val_loss: 0.1125 - val_accuracy: 0.9652 - val_precision: 0.9652 - val_recall: 0.9652 - val_auc: 0.9846\n",
      "Epoch 12/30\n",
      "574/574 [==============================] - 1608s 3s/step - loss: 0.1177 - accuracy: 0.9630 - precision: 0.9630 - recall: 0.9630 - auc: 0.9840 - val_loss: 0.1105 - val_accuracy: 0.9662 - val_precision: 0.9662 - val_recall: 0.9662 - val_auc: 0.9842\n",
      "Epoch 13/30\n",
      "574/574 [==============================] - 1535s 3s/step - loss: 0.1141 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - auc: 0.9848 - val_loss: 0.1040 - val_accuracy: 0.9667 - val_precision: 0.9667 - val_recall: 0.9667 - val_auc: 0.9849\n",
      "Epoch 14/30\n",
      "574/574 [==============================] - 1076s 2s/step - loss: 0.1103 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - auc: 0.9856 - val_loss: 0.1005 - val_accuracy: 0.9684 - val_precision: 0.9684 - val_recall: 0.9684 - val_auc: 0.9867\n",
      "Epoch 15/30\n",
      "574/574 [==============================] - 1160s 2s/step - loss: 0.1053 - accuracy: 0.9673 - precision: 0.9673 - recall: 0.9673 - auc: 0.9861 - val_loss: 0.0957 - val_accuracy: 0.9693 - val_precision: 0.9693 - val_recall: 0.9693 - val_auc: 0.9870\n",
      "Epoch 16/30\n",
      "574/574 [==============================] - 1148s 2s/step - loss: 0.1008 - accuracy: 0.9680 - precision: 0.9680 - recall: 0.9680 - auc: 0.9873 - val_loss: 0.0872 - val_accuracy: 0.9727 - val_precision: 0.9727 - val_recall: 0.9727 - val_auc: 0.9898\n",
      "Epoch 17/30\n",
      "574/574 [==============================] - 1119s 2s/step - loss: 0.0978 - accuracy: 0.9687 - precision: 0.9687 - recall: 0.9687 - auc: 0.9877 - val_loss: 0.0876 - val_accuracy: 0.9726 - val_precision: 0.9726 - val_recall: 0.9726 - val_auc: 0.9881\n",
      "Epoch 18/30\n",
      "574/574 [==============================] - 1013s 2s/step - loss: 0.0932 - accuracy: 0.9700 - precision: 0.9700 - recall: 0.9700 - auc: 0.9885 - val_loss: 0.0820 - val_accuracy: 0.9729 - val_precision: 0.9729 - val_recall: 0.9729 - val_auc: 0.9900\n",
      "Epoch 19/30\n",
      "574/574 [==============================] - 936s 2s/step - loss: 0.0884 - accuracy: 0.9716 - precision: 0.9716 - recall: 0.9716 - auc: 0.9893 - val_loss: 0.0802 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744 - val_auc: 0.9906\n",
      "Epoch 20/30\n",
      "574/574 [==============================] - 944s 2s/step - loss: 0.0865 - accuracy: 0.9716 - precision: 0.9716 - recall: 0.9716 - auc: 0.9896 - val_loss: 0.0730 - val_accuracy: 0.9756 - val_precision: 0.9756 - val_recall: 0.9756 - val_auc: 0.9918\n",
      "Epoch 21/30\n",
      "574/574 [==============================] - 968s 2s/step - loss: 0.0824 - accuracy: 0.9729 - precision: 0.9729 - recall: 0.9729 - auc: 0.9903 - val_loss: 0.0686 - val_accuracy: 0.9770 - val_precision: 0.9770 - val_recall: 0.9770 - val_auc: 0.9924\n",
      "Epoch 22/30\n",
      "574/574 [==============================] - 974s 2s/step - loss: 0.0791 - accuracy: 0.9740 - precision: 0.9740 - recall: 0.9740 - auc: 0.9910 - val_loss: 0.0670 - val_accuracy: 0.9774 - val_precision: 0.9774 - val_recall: 0.9774 - val_auc: 0.9920\n",
      "Epoch 23/30\n",
      "574/574 [==============================] - 927s 2s/step - loss: 0.0742 - accuracy: 0.9751 - precision: 0.9751 - recall: 0.9751 - auc: 0.9918 - val_loss: 0.0614 - val_accuracy: 0.9794 - val_precision: 0.9794 - val_recall: 0.9794 - val_auc: 0.9940\n",
      "Epoch 24/30\n",
      "574/574 [==============================] - 898s 2s/step - loss: 0.0712 - accuracy: 0.9763 - precision: 0.9763 - recall: 0.9763 - auc: 0.9922 - val_loss: 0.0623 - val_accuracy: 0.9787 - val_precision: 0.9787 - val_recall: 0.9787 - val_auc: 0.9927\n",
      "Epoch 25/30\n",
      "574/574 [==============================] - 897s 2s/step - loss: 0.0688 - accuracy: 0.9770 - precision: 0.9770 - recall: 0.9770 - auc: 0.9926 - val_loss: 0.0539 - val_accuracy: 0.9817 - val_precision: 0.9817 - val_recall: 0.9817 - val_auc: 0.9950\n",
      "Epoch 26/30\n",
      "574/574 [==============================] - 898s 2s/step - loss: 0.0649 - accuracy: 0.9777 - precision: 0.9777 - recall: 0.9777 - auc: 0.9933 - val_loss: 0.0492 - val_accuracy: 0.9822 - val_precision: 0.9822 - val_recall: 0.9822 - val_auc: 0.9952\n",
      "Epoch 27/30\n",
      "574/574 [==============================] - 897s 2s/step - loss: 0.0607 - accuracy: 0.9785 - precision: 0.9785 - recall: 0.9785 - auc: 0.9943 - val_loss: 0.0477 - val_accuracy: 0.9819 - val_precision: 0.9819 - val_recall: 0.9819 - val_auc: 0.9963\n",
      "Epoch 28/30\n",
      "574/574 [==============================] - 896s 2s/step - loss: 0.0579 - accuracy: 0.9794 - precision: 0.9794 - recall: 0.9794 - auc: 0.9947 - val_loss: 0.0451 - val_accuracy: 0.9833 - val_precision: 0.9833 - val_recall: 0.9833 - val_auc: 0.9967\n",
      "Epoch 29/30\n",
      "574/574 [==============================] - 897s 2s/step - loss: 0.0545 - accuracy: 0.9805 - precision: 0.9805 - recall: 0.9805 - auc: 0.9951 - val_loss: 0.0508 - val_accuracy: 0.9809 - val_precision: 0.9809 - val_recall: 0.9809 - val_auc: 0.9949\n",
      "Epoch 30/30\n",
      "574/574 [==============================] - 897s 2s/step - loss: 0.0512 - accuracy: 0.9817 - precision: 0.9817 - recall: 0.9817 - auc: 0.9956 - val_loss: 0.0392 - val_accuracy: 0.9850 - val_precision: 0.9850 - val_recall: 0.9850 - val_auc: 0.9973\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(4000,1))\n",
    "seq1 = input1\n",
    "\n",
    "seq1 = Conv1D(64,8, padding='SAME',activation='relu')(seq1)\n",
    "seq1 = CBAM(seq1,64,8)\n",
    "seq1 = MaxPooling1D(4)(seq1)\n",
    "\n",
    "seq1 = Conv1D(128,8, padding='SAME',activation='relu')(seq1)\n",
    "seq1 = CBAM(seq1,128,8)\n",
    "seq1 = MaxPooling1D(4)(seq1)\n",
    "\n",
    "seq1 = Conv1D(256,8, padding='SAME',activation='relu')(seq1)\n",
    "seq1 = CBAM(seq1,256,8)\n",
    "seq1 = MaxPooling1D(4)(seq1)\n",
    "\n",
    "seq1 = LSTM(128, return_sequences=True)(seq1)\n",
    "seq1 = Flatten()(seq1)\n",
    "\n",
    "input2 = Input(shape=(1000,1))\n",
    "seq2 = input2\n",
    "seq2 = Conv1D(32,8, padding='SAME',activation='relu')(seq2)\n",
    "seq2 = CBAM(seq2,32,8)\n",
    "seq2 = MaxPooling1D(4)(seq2)\n",
    "\n",
    "seq2 = Conv1D(64,8, padding='SAME',activation='relu')(seq2)\n",
    "seq2 = CBAM(seq2,64,8)\n",
    "seq2 = MaxPooling1D(4)(seq2)\n",
    "\n",
    "seq2 = LSTM(64, return_sequences=True)(seq2)\n",
    "seq2 = Flatten()(seq2)\n",
    "seq2 = RepeatVector(2)(seq2)\n",
    "seq2 = Flatten()(seq2)\n",
    "\n",
    "add = Add()([seq1,seq2])\n",
    "seq = Dense(1024, activation='sigmoid')(add)\n",
    "seq = Dropout(0.5)(seq)\n",
    "\n",
    "output_tensor = Dense(2, activation='softmax')(seq)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=output_tensor)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(1e-3, amsgrad=True), metrics=METRICS)\n",
    "history = model.fit([f_trainX,g_trainX],f_trainY, epochs=ep,validation_data = ([f_testX,g_testX],f_testY), workers=4, use_multiprocessing=True,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------保存----------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------保存----------\")\n",
    "model.save(\"./model/model1.keras\")\n",
    "with open('./history/model1History.txt', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cae380bebe6226c23c606d6f31ea40e17fed3962063ae5af630e3d6f79419451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
